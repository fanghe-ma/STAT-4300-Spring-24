\chapter{Class 12}

\section{Expectation}
\begin{framed}
   \textbf{Definition}: the expected value of a discrete r.v. $X$ whose possible values are $x_1, x_2, \hdots$ is
   \[
      E[X] = \sum_{i = 1}^{\infty} x_i P(X = x_i)
   \] 
\end{framed}

\subsection{Linearity of expectation}

\begin{framed}
   \textbf{Theorem}: For any $X, Y$ and constant $c$, 
   \[
     E\left[ X + Y\right]  = E\left[ X \right]  + E\left[ Y\right] 
   \] 
   \[
     E\left[ cX\right]  = c E\left[ X\right] 
   \] 
\end{framed}

\section{Geometric distribution}

\begin{framed}
   \textbf{Definition}: For a sequence of independent Bernoulli trials, each with the same success probability, let $X$ denote the number of trials before the first success, $X$ has the geometric distribution with parameter $p$ 
   \[
     X \sim Geom(p)
   \] 
   \[
     X + 1 \sim FS(p)
   \] 

   The PMF is 
   \[
     P(X = k) =  (1-p)^k  \cdot p
   \] 

   The expectation is 
   \[
      E[X] = \frac{1 - p}{p}
   \] 

   
  
\end{framed}





